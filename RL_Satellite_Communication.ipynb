{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRe+TOyRSkRrEe29/zbs3i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7sK6WkyFOJ4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Q-learning agent for satellite frequency optimization\n",
        "class RLAgent:\n",
        "    def __init__(self, state_space, action_space):\n",
        "        self.q_table = np.zeros((state_space, action_space))\n",
        "        self.learning_rate = 0.1\n",
        "        self.discount_factor = 0.9\n",
        "        self.exploration_rate = 1.0\n",
        "        self.exploration_decay = 0.995\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.uniform(0, 1) < self.exploration_rate:\n",
        "            return random.choice(range(self.q_table.shape[1]))\n",
        "        return np.argmax(self.q_table[state])\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        best_next_action = np.argmax(self.q_table[next_state])\n",
        "        self.q_table[state, action] = self.q_table[state, action] + \\\n",
        "            self.learning_rate * (reward + self.discount_factor * self.q_table[next_state, best_next_action] - self.q_table[state, action])\n",
        "\n",
        "# Example Simulation\n",
        "state_space = 5 # Example states (e.g., weather conditions)\n",
        "action_space = 3 # Example actions (e.g., satellite frequency adjustments)\n",
        "\n",
        "for episode in range(1000):  # Simulate episodes\n",
        "    state = random.randint(0, state_space-1)\n",
        "    action = agent.choose_action(state)\n",
        "    reward = random.uniform(0, 1)  # Example reward for frequency optimization\n",
        "    next_state = random.randint(0, state_space-1)\n",
        "    agent.update_q_table(state, action, reward, next_state)\n",
        "    agent.exploration_rate *= agent.exploration_decay\n",
        "\n",
        "print(\"Final Q-Table: \", agent.q_table)\n"
      ]
    }
  ]
}